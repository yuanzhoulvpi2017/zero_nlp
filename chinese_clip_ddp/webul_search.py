from embedding.data import ImageTextDataset, ImageTextDataCollator
from embedding.model import TextModelEmbedding, ImageModelEmbedding
from pathlib import Path
import torch
from PIL import Image
from tqdm.auto import tqdm
import numpy as np
import pandas as pd
from typing import List
from pymilvus import MilvusClient
import streamlit as st
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
from dataclasses import dataclass


st.set_page_config(
    page_icon="ğŸ”",
    page_title="mivlus å›¾æ–‡ Search",
    layout="wide",
)


@dataclass
class MilvusConfig:
    DB_PATH: str = "milvus_data/milvus_data.db"
    TABLE_NAME: str = "image_match_1216"
    DIM_VALUE: str = 1024


milvus_config = MilvusConfig()


@st.cache_resource
def load_text_embedding_model():
    text_embedding_model_path = "models/BAAI/bge-large-zh-v1.5"

    device = "cuda:0"
    text_embedding_model = TextModelEmbedding(text_embedding_model_path, device)
    return text_embedding_model


@st.cache_resource
def load_milvus_engine():
    client = MilvusClient(uri=milvus_config.DB_PATH)

    return client


def plot_images_with_scores(images, scores, rows=1, cols=None):
    """
    å±•ç¤ºå¤šä¸ªå›¾ç‰‡å¹¶æ˜¾ç¤ºå¯¹åº”çš„åˆ†æ•°

    å‚æ•°:
    - images: å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ (List[Path])
    - scores: å¯¹åº”çš„åˆ†æ•°åˆ—è¡¨
    - rows: è¡Œæ•°ï¼ˆé»˜è®¤ä¸º1ï¼‰
    - cols: åˆ—æ•°ï¼ˆé»˜è®¤ä¸ºNoneï¼Œå°†è‡ªåŠ¨è®¡ç®—ï¼‰
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šåˆ—æ•°ï¼Œè‡ªåŠ¨è®¡ç®—
    if cols is None:
        cols = len(images)

    # åˆ›å»ºå›¾å½¢å’Œå­å›¾
    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))

    # å¦‚æœåªæœ‰ä¸€å¼ å›¾ï¼Œå°†axesè½¬æ¢ä¸ºæ•°ç»„
    if rows == 1 and cols == 1:
        axes = np.array([[axes]])
    elif rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)

    # éå†å¹¶æ˜¾ç¤ºå›¾ç‰‡
    for i in range(rows):
        for j in range(cols):
            idx = i * cols + j
            if idx < len(images):
                # è¯»å–å›¾ç‰‡
                img = mpimg.imread(str(images[idx]))

                # æ˜¾ç¤ºå›¾ç‰‡
                axes[i, j].imshow(img)
                axes[i, j].axis("off")

                # æ·»åŠ åˆ†æ•°æ ‡ç­¾
                axes[i, j].set_title(f"Score: {scores[idx]:.4f}", fontsize=20)

    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    plt.show()
    return fig


text_embedding_model = load_text_embedding_model()
milvus_client = load_milvus_engine()


def convert_text2embedding(text: str, normalize: bool = True):
    with torch.inference_mode():
        text_embedding = (
            text_embedding_model(
                encoded_input=None, sentences=[text], normalize_embeddings=normalize
            )
            .cpu()
            .numpy()
        )
        return text_embedding


def func1():
    with st.spinner("æ­£åœ¨æœç´¢ä¸­..."):
        with st.chat_message("user"):
            st.markdown(f"æœç´¢å…³é”®è¯: {st.session_state.get('search_text')}")

        row_value, col_value = (
            st.session_state.get("row1"),
            st.session_state.get("col1"),
        )
        search_text = st.session_state.get("search_text")
        text_embedding = convert_text2embedding(search_text)
        res = milvus_client.search(
            collection_name=milvus_config.TABLE_NAME,
            data=[text_embedding.flatten().tolist()],
            limit=row_value * col_value,
            output_fields=["id", "text"],
        )[0]

        test_df = pd.DataFrame.from_dict(res).pipe(
            lambda x: x.assign(
                **{"image_path": x["entity"].apply(lambda j: j.get("text"))}
            )
        )

        image_paths = test_df["image_path"].tolist()

        scores = test_df["distance"].tolist()

        fig = plot_images_with_scores(
            image_paths,
            scores,
            rows=col_value,
            cols=row_value,
        )
        st.session_state["search_data"] = test_df

        with st.chat_message("ai"):
            tab1, tab2 = st.tabs(["å›¾ç‰‡", "è¡¨æ ¼"])
            with tab1:
                st.pyplot(fig)

            with tab2:
                st.table(
                    st.session_state["search_data"][["id", "distance", "image_path"]]
                )


with st.sidebar:
    st.title("å›¾æ–‡æœç´¢")
    st.markdown(
        "[å…³æ³¨bç«™: è‰¯ç¦è·¯ç¨‹åºå‘˜](https://space.bilibili.com/45156039?spm_id_from=333.1007.0.0)"
    )
    st.number_input(
        label="æ˜¾ç¤ºå¤šå°‘åˆ—å›¾ç‰‡", value=3, min_value=2, max_value=6, step=1, key="col1"
    )
    st.number_input(
        label="æ˜¾ç¤ºå¤šå°‘è¡Œå›¾ç‰‡", value=5, min_value=2, max_value=10, step=1, key="row1"
    )


st.chat_input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼š", key="search_text", on_submit=func1)
