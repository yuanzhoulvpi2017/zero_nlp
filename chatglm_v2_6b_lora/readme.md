# ğŸš€ æœ€ç®€å•ã€æœ€ä¾¿å®œçš„è®­ç»ƒ`chatglm-6b`æ¨¡å‹æ•™ç¨‹ ğŸ¯

1. æ„Ÿè°¢æ™ºè°±AIå¼€æº`chatglm-v2-6b`å¤§æ¨¡å‹ï¼›
2. ä¹‹å‰å°±ç»™`v1`ç‰ˆæœ¬åšè¿‡loraï¼Œåœ¨æ™ºè°±AIå®£å¸ƒ`v2`å¯ä»¥å•†ç”¨åï¼Œæ‰“ç®—ç»™`v2`ä¹Ÿåšä¸€ç‰ˆloraï¼›
3. åŸºäº`v2`çš„[å®˜ç½‘ä»£ç ](https://github.com/THUDM/ChatGLM2-6B/tree/main/ptuning)ï¼Œåšäº†ç®€å•ä¿®æ”¹ï¼›

## ğŸ“ æ›´æ–°è®°å½•

1. **07-14 ç‰ˆæœ¬** `chatglm-v2-6b`æ¨¡å‹çš„`lora`è®­ç»ƒæ–¹æ¡ˆğŸ”—ğŸ‘‰[**chatglm_v2_6b_lora
   **](https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora)
2. **07-17 ç‰ˆæœ¬** æ·»åŠ äº†æ¨¡å‹å¹¶è¡Œè®­ç»ƒloraä»£ç ï¼Œé€šè¿‡`--model_parallel_mode True`æ‰“å¼€

# ğŸ”„ è®­ç»ƒ

## ä¸‹è½½æ•°æ®é›†

ADGEN æ•°æ®é›†ä»»åŠ¡ä¸ºæ ¹æ®è¾“å…¥ï¼ˆcontentï¼‰ç”Ÿæˆä¸€æ®µå¹¿å‘Šè¯ï¼ˆsummaryï¼‰ã€‚

```json
{
  "content": "ç±»å‹#ä¸Šè¡£*ç‰ˆå‹#å®½æ¾*ç‰ˆå‹#æ˜¾ç˜¦*å›¾æ¡ˆ#çº¿æ¡*è¡£æ ·å¼#è¡¬è¡«*è¡£è¢–å‹#æ³¡æ³¡è¢–*è¡£æ¬¾å¼#æŠ½ç»³",
  "summary": "è¿™ä»¶è¡¬è¡«çš„æ¬¾å¼éå¸¸çš„å®½æ¾ï¼Œåˆ©è½çš„çº¿æ¡å¯ä»¥å¾ˆå¥½çš„éšè—èº«æä¸Šçš„å°ç¼ºç‚¹ï¼Œç©¿åœ¨èº«ä¸Šæœ‰ç€å¾ˆå¥½çš„æ˜¾ç˜¦æ•ˆæœã€‚é¢†å£è£…é¥°äº†ä¸€ä¸ªå¯çˆ±çš„æŠ½ç»³ï¼Œæ¼‚äº®çš„ç»³ç»“å±•ç°å‡ºäº†åè¶³çš„ä¸ªæ€§ï¼Œé…åˆæ—¶å°šçš„æ³¡æ³¡è¢–å‹ï¼Œå°½æ˜¾å¥³æ€§ç”œç¾å¯çˆ±çš„æ°”æ¯ã€‚"
}
```

ä» [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing)
æˆ–è€… [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) ä¸‹è½½å¤„ç†å¥½çš„ ADGEN
æ•°æ®é›†ï¼Œå°†è§£å‹åçš„ `AdvertiseGen` ç›®å½•æ”¾åˆ°æœ¬ç›®å½•ä¸‹ã€‚

## ç¡¬ä»¶è¦æ±‚

1. **æœ‰ä¸ª`3090`æ˜¾å¡å³å¯ï¼ˆ24Gæ˜¾å­˜å·¦å³ï¼‰**
2. åœ¨ä¸‹é¢è¿™ä¸ªå‚æ•°ä¸‹ï¼Œæ˜¾å­˜åªéœ€è¦`14G`

```sh
    --max_source_length 64 \
    --max_target_length 128 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \ 
    --lora_r 32

```

## è®­ç»ƒè„šæœ¬

1. ä½¿ç”¨vscodeè°ƒè¯•ï¼Œå°±åœ¨`.vscode/launch.json`é‡Œé¢ï¼›
2. ç›´æ¥ä½¿ç”¨shï¼Œ`sh train.sh`

# ğŸšœ æ¨ç†

1. ä½¿ç”¨æ–‡ä»¶ï¼š`infer_lora.ipynb`

### ä½¿ç”¨`lora`æ¨ç†

```python
from transformers import AutoTokenizer, AutoModel
from peft import PeftModel, PeftConfig
import torch
import os

os.environ['CUDA_VISIBLE_DEVICES'] = '1'

# åŸå§‹çš„æ¨¡å‹è·¯å¾„
model_name_or_path = "/media/yuanz/æ–°åŠ å·/è®­ç»ƒä»£ç /chatglm6b_v2_0716/chatglm2-6b_model"

# è®­ç»ƒåçš„loraä¿å­˜çš„è·¯å¾„
peft_model_id = "output/adgen-chatglm2-6b-lora_version/checkpoint-880"

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='auto',
                                  torch_dtype=torch.bfloat16)  # .half().cuda()

model = PeftModel.from_pretrained(model, peft_model_id)
model = model.eval()

response, history = model.chat(tokenizer, "ç±»å‹#ä¸Šè¡£*æè´¨#ç‰›ä»”å¸ƒ*é¢œè‰²#ç™½è‰²*é£æ ¼#ç®€çº¦*å›¾æ¡ˆ#åˆºç»£*è¡£æ ·å¼#å¤–å¥—*è¡£æ¬¾å¼#ç ´æ´",
                               history=[])
print(response)
```

# ğŸ˜± è¡€çš„æ•™è®­

1. ä¸€å®šè¦ä»`huggingface`ä¸ŠæŠŠ[`chatglm-v2-6b`çš„æ‰€æœ‰æ–‡ä»¶](https://huggingface.co/THUDM/chatglm2-6b/tree/main)éƒ½ä¸‹è½½ä¸‹æ¥ï¼Œæ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼›è¿™æ ·å³ä½¿ä»–æ›´æ–°äº†ï¼Œä¹Ÿä¸ä¼šå½±å“åˆ°ä½ ã€‚å¦‚æœä½ ä¸ä¸‹è½½ï¼Œä½ ä¼šå¾ˆè¢«åŠ¨ğŸ˜’