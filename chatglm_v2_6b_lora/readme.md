# ğŸš€ æœ€ç®€å•ã€æœ€ä¾¿å®œçš„è®­ç»ƒ`chatglm-6b`æ¨¡å‹æ•™ç¨‹ ğŸ¯

1. æ„Ÿè°¢æ™ºè°±AIå¼€æº`chatglm-v2-6b`å¤§æ¨¡å‹ï¼›
2. ä¹‹å‰å°±ç»™`v1`ç‰ˆæœ¬åšè¿‡loraï¼Œåœ¨æ™ºè°±AIå®£å¸ƒ`v2`å¯ä»¥å•†ç”¨åï¼Œæ‰“ç®—ç»™`v2`ä¹Ÿåšä¸€ç‰ˆloraï¼›
3. åŸºäº`v2`çš„[å®˜ç½‘ä»£ç ](https://github.com/THUDM/ChatGLM2-6B/tree/main/ptuning)ï¼Œåšäº†ç®€å•ä¿®æ”¹ï¼›

## ğŸ“ æ›´æ–°è®°å½•


### **07-14 ç‰ˆæœ¬** Loraè®­ç»ƒæ–¹æ¡ˆ
`chatglm-v2-6b`æ¨¡å‹çš„`lora`è®­ç»ƒæ–¹æ¡ˆğŸ”—ğŸ‘‰[**chatglm_v2_6b_lora**](https://github.com/yuanzhoulvpi2017/zero_nlp/tree/main/chatglm_v2_6b_lora)
### **07-17 ç‰ˆæœ¬** æ·»åŠ æ¨¡å‹å¹¶è¡Œ
æ·»åŠ äº†æ¨¡å‹å¹¶è¡Œè®­ç»ƒloraä»£ç ï¼Œé€šè¿‡`--model_parallel_mode True`æ‰“å¼€
<details><summary><b>ğŸš¨æ³¨æ„ğŸš¨</b></summary>

æ·»åŠ äº†ä¸Šé¢çš„å‚æ•°ï¼Œç¡®å®å¯ä»¥è¿›è¡Œæ¨¡å‹å¹¶è¡Œï¼Œä½†æ˜¯ï¼Œè¿™æ˜¯åœ¨`chatglm`æ¨¡å‹ä»£ç æ²¡æœ‰bugçš„æƒ…å†µä¸‹ï¼Œç›®å‰å·²ç»å®šä½åˆ°bugï¼Œå¹¶ä¸”ä¿®å¤äº†bugï¼Œæˆ‘ä¹Ÿæäº¤PRç»™chatglmå›¢é˜Ÿï¼Œå¯ä»¥ç‚¹å‡»è¿™ä¸ªé“¾æ¥æŸ¥çœ‹[https://huggingface.co/THUDM/chatglm2-6b/discussions/54#64b542b05c1ffb087056001c](https://huggingface.co/THUDM/chatglm2-6b/discussions/54#64b542b05c1ffb087056001c)

è€ƒè™‘åˆ°ä»–ä»¬å›¢é˜Ÿæ•ˆç‡é—®é¢˜ï¼Œå¦‚æœä»–ä»¬è¿˜æ²¡æœ‰ä¿®æ”¹è¿™ä¸ªbugï¼Œé‚£ä½ ä»¬å¯ä»¥è‡ªå·±ä¿®æ”¹ï¼Œä¸»è¦æ˜¯è¿™ä¹ˆåšï¼š

åœ¨`modeling_chatglm.py`çš„ç¬¬`955`è¡Œä»£ç é™„è¿‘ï¼ˆä¹Ÿå°±æ˜¯`modeling_chatglm.py/ChatGLMForConditionalGeneration.forward`çš„`loss`éƒ¨åˆ†ï¼‰ï¼š

åŸå§‹ä»£ç :
```python

        loss = None
        if labels is not None:
            lm_logits = lm_logits.to(torch.float32)

            # Shift so that tokens < n predict n
            shift_logits = lm_logits[..., :-1, :].contiguous()   
            shift_labels = labels[..., 1:].contiguous() #<<<------------------çœ‹è¿™é‡Œ
            # Flatten the tokens
            loss_fct = CrossEntropyLoss(ignore_index=-100)
            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))

            lm_logits = lm_logits.to(hidden_states.dtype)
            loss = loss.to(hidden_states.dtype)

        if not return_dict:
            output = (lm_logits,) + transformer_outputs[1:]
            return ((loss,) + output) if loss is not None else output

        return CausalLMOutputWithPast(
            loss=loss,
            logits=lm_logits,
            past_key_values=transformer_outputs.past_key_values,
            hidden_states=transformer_outputs.hidden_states,
            attentions=transformer_outputs.attentions,
        )
```

ä¿®æ”¹ä¸º:

```python

        loss = None
        if labels is not None:
            lm_logits = lm_logits.to(torch.float32)

            # Shift so that tokens < n predict n
            shift_logits = lm_logits[..., :-1, :].contiguous()
            shift_labels = labels[..., 1:].contiguous().to(shift_logits.device) #<<<--------------------çœ‹è¿™é‡Œ
            # Flatten the tokens
            loss_fct = CrossEntropyLoss(ignore_index=-100)
            loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))

            lm_logits = lm_logits.to(hidden_states.dtype)
            loss = loss.to(hidden_states.dtype)

        if not return_dict:
            output = (lm_logits,) + transformer_outputs[1:]
            return ((loss,) + output) if loss is not None else output

        return CausalLMOutputWithPast(
            loss=loss,
            logits=lm_logits,
            past_key_values=transformer_outputs.past_key_values,
            hidden_states=transformer_outputs.hidden_states,
            attentions=transformer_outputs.attentions,
        )
```
æ˜¯çš„ï¼Œå°±ä¿®æ”¹é‚£ä¸€è¡Œå³å¯
![Alt text](images/image.png)

ç„¶åå°±å¯ä»¥æ­£å¸¸è·‘èµ·æ¥äº†ï½


</details>

# ğŸ”„ è®­ç»ƒ

## ä¸‹è½½æ•°æ®é›†

ADGEN æ•°æ®é›†ä»»åŠ¡ä¸ºæ ¹æ®è¾“å…¥ï¼ˆcontentï¼‰ç”Ÿæˆä¸€æ®µå¹¿å‘Šè¯ï¼ˆsummaryï¼‰ã€‚

```json
{
  "content": "ç±»å‹#ä¸Šè¡£*ç‰ˆå‹#å®½æ¾*ç‰ˆå‹#æ˜¾ç˜¦*å›¾æ¡ˆ#çº¿æ¡*è¡£æ ·å¼#è¡¬è¡«*è¡£è¢–å‹#æ³¡æ³¡è¢–*è¡£æ¬¾å¼#æŠ½ç»³",
  "summary": "è¿™ä»¶è¡¬è¡«çš„æ¬¾å¼éå¸¸çš„å®½æ¾ï¼Œåˆ©è½çš„çº¿æ¡å¯ä»¥å¾ˆå¥½çš„éšè—èº«æä¸Šçš„å°ç¼ºç‚¹ï¼Œç©¿åœ¨èº«ä¸Šæœ‰ç€å¾ˆå¥½çš„æ˜¾ç˜¦æ•ˆæœã€‚é¢†å£è£…é¥°äº†ä¸€ä¸ªå¯çˆ±çš„æŠ½ç»³ï¼Œæ¼‚äº®çš„ç»³ç»“å±•ç°å‡ºäº†åè¶³çš„ä¸ªæ€§ï¼Œé…åˆæ—¶å°šçš„æ³¡æ³¡è¢–å‹ï¼Œå°½æ˜¾å¥³æ€§ç”œç¾å¯çˆ±çš„æ°”æ¯ã€‚"
}
```

ä» [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing)
æˆ–è€… [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) ä¸‹è½½å¤„ç†å¥½çš„ ADGEN
æ•°æ®é›†ï¼Œå°†è§£å‹åçš„ `AdvertiseGen` ç›®å½•æ”¾åˆ°æœ¬ç›®å½•ä¸‹ã€‚

## ç¡¬ä»¶è¦æ±‚

1. **æœ‰ä¸ª`3090`æ˜¾å¡å³å¯ï¼ˆ24Gæ˜¾å­˜å·¦å³ï¼‰**
2. åœ¨ä¸‹é¢è¿™ä¸ªå‚æ•°ä¸‹ï¼Œæ˜¾å­˜åªéœ€è¦`14G`

```sh
    --max_source_length 64 \
    --max_target_length 128 \
    --per_device_train_batch_size 1 \
    --per_device_eval_batch_size 1 \ 
    --lora_r 32

```

## è®­ç»ƒè„šæœ¬

1. ä½¿ç”¨vscodeè°ƒè¯•ï¼Œå°±åœ¨`.vscode/launch.json`é‡Œé¢ï¼›
2. ç›´æ¥ä½¿ç”¨shï¼Œ`sh train.sh`

# ğŸšœ æ¨ç†

1. ä½¿ç”¨æ–‡ä»¶ï¼š`infer_lora.ipynb`

### ä½¿ç”¨`lora`æ¨ç†

```python
from transformers import AutoTokenizer, AutoModel
from peft import PeftModel, PeftConfig
import torch
import os

os.environ['CUDA_VISIBLE_DEVICES'] = '1'

# åŸå§‹çš„æ¨¡å‹è·¯å¾„
model_name_or_path = "/media/yuanz/æ–°åŠ å·/è®­ç»ƒä»£ç /chatglm6b_v2_0716/chatglm2-6b_model"

# è®­ç»ƒåçš„loraä¿å­˜çš„è·¯å¾„
peft_model_id = "output/adgen-chatglm2-6b-lora_version/checkpoint-880"

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='auto',
                                  torch_dtype=torch.bfloat16)  # .half().cuda()

model = PeftModel.from_pretrained(model, peft_model_id)
model = model.eval()

response, history = model.chat(tokenizer, "ç±»å‹#ä¸Šè¡£*æè´¨#ç‰›ä»”å¸ƒ*é¢œè‰²#ç™½è‰²*é£æ ¼#ç®€çº¦*å›¾æ¡ˆ#åˆºç»£*è¡£æ ·å¼#å¤–å¥—*è¡£æ¬¾å¼#ç ´æ´",
                               history=[])
print(response)
```

# ğŸ˜± è¡€çš„æ•™è®­

1. ä¸€å®šè¦ä»`huggingface`ä¸ŠæŠŠ[`chatglm-v2-6b`çš„æ‰€æœ‰æ–‡ä»¶](https://huggingface.co/THUDM/chatglm2-6b/tree/main)éƒ½ä¸‹è½½ä¸‹æ¥ï¼Œæ”¾åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼›è¿™æ ·å³ä½¿ä»–æ›´æ–°äº†ï¼Œä¹Ÿä¸ä¼šå½±å“åˆ°ä½ ã€‚å¦‚æœä½ ä¸ä¸‹è½½ï¼Œä½ ä¼šå¾ˆè¢«åŠ¨ğŸ˜’


## ğŸ•¸ï¸ ç›¸å…³çš„BUG

å¾ˆå¤šäººåœ¨è·‘å¤šå¡çš„æ—¶å€™ï¼Œä¼šé‡åˆ°ä¸€äº›è«åå…¶å¦™çš„é”™è¯¯ï¼Œå»ºè®®æ‚¨æŒ‰ç…§ä¸‹é¢ä¸¤ä¸ªæ­¥éª¤è¿›è¡Œæ’æŸ¥ï¼š
1. ä¸€å®šè¦çœ‹æˆ‘ä¸Šé¢æŠ˜å çš„é‚£ä¸€å—ä¸œè¥¿ï¼Œå°±æ˜¯`ğŸš¨æ³¨æ„`éƒ¨åˆ†ã€‚
2. æ£€æŸ¥`transformers`çš„ç‰ˆæœ¬ï¼Œå¦‚æœå¤ªä½ï¼Œå°±æ›´æ–°ä¸€ä¸‹ï¼Œå»ºè®®æ›´æ–°ï¼š`pip install transformers -U`

å¦‚æœä¸Šé¢ä¸¤ä¸ªæ­¥éª¤éƒ½æ²¡æœ‰è§£å†³æ‚¨çš„bugï¼Œæ¬¢è¿æ‚¨æå‡º`issue`ï¼Œæˆ‘ä¼šåœ¨ç¬¬ä¸€æ—¶é—´è¿›è¡Œå›å¤ï½
